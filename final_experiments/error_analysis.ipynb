{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNk6qTGvYYMFQXog/27ji/W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"PQ-KVRpeWfny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503034007,"user_tz":-240,"elapsed":23144,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"7f6d3c7f-912b-4f6d-8056-41a421602db2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"soMHvsil-0U6","executionInfo":{"status":"ok","timestamp":1715503035291,"user_tz":-240,"elapsed":1291,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"outputs":[],"source":["import pandas as pd\n","\n","from tqdm import tqdm\n","import re\n","from sklearn.metrics import classification_report\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","\n","import math\n","\n","from sklearn.metrics import f1_score, accuracy_score, classification_report\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import os\n","\n"]},{"cell_type":"code","source":["!pip install camel-kenlm==2023.3.17.2"],"metadata":{"id":"8S7cNLH-4HSX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503146028,"user_tz":-240,"elapsed":110744,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"d01a8c83-115d-4923-a269-bc97edd3ff8b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting camel-kenlm==2023.3.17.2\n","  Downloading camel-kenlm-2023.3.17.2.tar.gz (426 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/426.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/426.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m419.8/426.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: camel-kenlm\n","  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for camel-kenlm: filename=camel_kenlm-2023.3.17.2-cp310-cp310-linux_x86_64.whl size=3453126 sha256=e464e99e11dcd7c22199a3a8481008f30fc1d44ad6b165cf973af26ada554a71\n","  Stored in directory: /root/.cache/pip/wheels/29/c5/32/09633c3b70fdfc470b2fb912bd9e90d8d6814df68c794dcaa6\n","Successfully built camel-kenlm\n","Installing collected packages: camel-kenlm\n","Successfully installed camel-kenlm-2023.3.17.2\n"]}]},{"cell_type":"code","source":["!pip install camel_tools\n","\n","from camel_tools.tokenizers.word import simple_word_tokenize\n","\n","os.environ['CAMELTOOLS_DATA'] = '/content/drive/MyDrive/camel_tools'"],"metadata":{"id":"95mbPh8M3Njf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503218901,"user_tz":-240,"elapsed":72881,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"de53269e-ff00-4903-c2f0-2cc794c9e5d3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting camel_tools\n","  Downloading camel_tools-1.5.2-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from camel_tools) (0.18.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.16.0)\n","Collecting docopt (from camel_tools)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from camel_tools) (5.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.11.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from camel_tools) (2.0.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.2.2)\n","Collecting dill (from camel_tools)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from camel_tools) (2.2.1+cu121)\n","Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from camel_tools) (4.40.2)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from camel_tools) (0.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from camel_tools) (2.31.0)\n","Collecting emoji (from camel_tools)\n","  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyrsistent (from camel_tools)\n","  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from camel_tools) (0.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from camel_tools) (4.66.4)\n","Collecting muddler (from camel_tools)\n","  Downloading muddler-0.1.3-py3-none-any.whl (16 kB)\n","Requirement already satisfied: camel-kenlm>=2023.3.17.2 in /usr/local/lib/python3.10/dist-packages (from camel_tools) (2023.3.17.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->camel_tools)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (0.4.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel_tools) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel_tools) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->camel_tools) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->camel_tools) (1.3.0)\n","Building wheels for collected packages: docopt\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=0894442c43a604460445ee2a783bbd58b31e017b18f72073935a0f145e9952b2\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built docopt\n","Installing collected packages: docopt, pyrsistent, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, muddler, emoji, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, camel_tools\n","Successfully installed camel_tools-1.5.2 dill-0.3.8 docopt-0.6.2 emoji-2.11.1 muddler-0.1.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pyrsistent-0.20.0\n"]}]},{"cell_type":"code","source":["!pip install Levenshtein\n","import Levenshtein\n","from camel_tools.morphology.database import MorphologyDB\n","from camel_tools.morphology.analyzer import Analyzer\n","from camel_tools.tokenizers.word import simple_word_tokenize\n","from camel_tools.disambig.mle import MLEDisambiguator\n","from camel_tools.disambig.bert import BERTUnfactoredDisambiguator\n","from pathlib import Path\n","S31_DB_PATH = Path('/content/drive/My Drive/capstone_data/disambig_db/calima-msa-s31.db')\n","S31_DB = MorphologyDB(S31_DB_PATH, 'a')\n","S31_AN = Analyzer(S31_DB, 'NOAN_ALL', cache_size=100000)\n","bert_disambig = BERTUnfactoredDisambiguator.pretrained('msa', top=1000, pretrained_cache = False)\n","bert_disambig._analyzer = S31_AN"],"metadata":{"id":"piZdFNQEWq4g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503264513,"user_tz":-240,"elapsed":45621,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"51f587cc-e21a-4b77-ad49-9debb60b6391"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Levenshtein\n","  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein)\n","  Downloading rapidfuzz-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n","Successfully installed Levenshtein-0.25.1 rapidfuzz-3.9.0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/camel_tools/data/disambig_bert_unfactored/msa were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["## train data\n","import numpy as np\n","words_train = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/train_wordwise_clean.csv')\n","words_dev = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/dev_wordwise_clean.csv')\n","words_test = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/test_wordwise_clean.csv')\n","\n","## testing data in fragments\n","frag_train = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/all_train_aligned.csv')\n","frag_dev = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/all_dev_aligned.csv')\n","frag_test = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/all_test_aligned.csv')\n","\n","\n","frag_train = frag_train[frag_train.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_dev = frag_dev[frag_dev.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_test = frag_test[frag_test.apply(lambda x: type(x['0']) == str, axis = 1)]"],"metadata":{"id":"apn68S4vVETY","executionInfo":{"status":"ok","timestamp":1715503269235,"user_tz":-240,"elapsed":4725,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","### save wordwise decisions\n","with open('/content/drive/My Drive/capstone_data/final_result/res_wordwise_decisions.pkl', 'rb') as f:\n","  res_wordwise_decisions = pickle.load(f)"],"metadata":{"id":"vKO3p3krVfwI","executionInfo":{"status":"ok","timestamp":1715503270370,"user_tz":-240,"elapsed":1139,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import pickle\n","with open('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/freq_token_db.pkl', 'rb') as f:\n","  freq_backoff = pickle.load(f)\n","with open('/content/drive/My Drive/capstone_data/disambig_db/all_levels_freq_binning_cumulative.pkl', 'rb') as f:\n","  words_and_levels_freq_binning_cum = pickle.load(f)\n","\n","alt_backoff = words_and_levels_freq_binning_cum[10000][0]\n","\n","def get_mle_counts_aligned(words, levels):\n","  dict_levels = {}\n","  for word, level in zip(words, levels):\n","      try:\n","          #assume every entry of dict_levels : {3: int, 4: int, 5: int}\n","          dict_levels[word][level] += 1\n","      except:\n","          dict_levels[word] = {3: 0, 4: 0, 5: 0}\n","          dict_levels[word][level] += 1\n","  return dict_levels\n","\n","def max_frequency_strategy(dict_levels, confidence = 0):\n","  print(confidence)\n","  dict_levels_max = {}\n","  no = 0\n","  for token in dict_levels.keys():\n","    cd = max(dict_levels[token].values())/sum(dict_levels[token].values())\n","    if cd >= confidence:\n","      dict_levels_max[token] = max(dict_levels[token].items(), key = lambda x: x[1])[0]\n","    else:\n","      no += 1\n","  print(no)\n","  return dict_levels_max\n","\n","def mle_training_pipeline_aligned(data, strategy, confidence = 0):\n","  counts = get_mle_counts_aligned(data['Word'], data['Label'])\n","  return strategy(counts, confidence = confidence)\n","\n","highest_model = mle_training_pipeline_aligned(words_train, max_frequency_strategy, confidence = 0.85)\n","\n","# configure lexicon\n","import pickle\n","with open('/content/drive/My Drive/capstone_data/disambig_db/quick_lemma_lookup.pkl', 'rb') as f:\n","    lemma_db = pickle.load(f)\n","\n","\n","def sort_score(list_of_analyses):\n","  list_of_analyses.sort(key = lambda x: x.score, reverse = True)\n","  highest_score = list_of_analyses[0].score\n","  analyses_with_equal_score = [x for x in list_of_analyses\n","                                if x.score == highest_score]\n","  return analyses_with_equal_score\n","\n","\n","def sort_lexlogprob(list_of_analyses):\n","  list_of_analyses.sort(key = lambda x: x.analysis['lex_logprob'], reverse=True)\n","  highest_prob = list_of_analyses[0].analysis['lex_logprob']\n","  analyses_with_equal_prob = [x for x in list_of_analyses\n","                                if x.analysis['lex_logprob'] == highest_prob]\n","  return analyses_with_equal_prob\n","\n","def default_level_oov(word, level, analysis):\n","  return level\n","\n","def sort_level(list_of_analyses):\n","  list_of_analyses.sort(key = lambda x: get_rl_single(x.analysis, 9999))\n","  lowest_rl = get_rl_single(list_of_analyses[0].analysis, 9999)\n","  analyses_with_equal_level = [x for x in list_of_analyses\n","                                    if get_rl_single(x.analysis, 9999) == lowest_rl]\n","  return analyses_with_equal_level\n","\n","def score_then_level_then_llp(list_of_analyses):\n","  list_of_analyses = sort_score(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_level(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_lexlogprob(list_of_analyses)\n","  return list_of_analyses[0].analysis\n","\n","def get_rl_0(token, analyses, oov_level = 0):\n","  return oov_level\n","\n","def get_rl_3(token, analyses, oov_level = 3):\n","  return oov_level\n","\n","def get_rl_4(token, analyses, oov_level = 4):\n","  return oov_level\n","\n","def get_rl_5(token, analyses, oov_level = 5):\n","  return oov_level\n","\n","def get_rl_mle(token, analyses, oov_level = 0):\n","    try:\n","        return highest_model[token]\n","    except:\n","        return oov_level\n","\n","def get_rl_alt_freq(token, analyses, oov_level = 0):\n","    try:\n","        return alt_backoff[token]\n","    except:\n","        return oov_level\n","\n","def get_rl_freq(token, analyses, oov_level = 0):\n","    try:\n","        return freq_backoff[token]\n","    except:\n","        return oov_level\n","\n","def get_rl_single(analysis, oov_level = 0):\n","  lex = analysis['lex']\n","  pos = analysis['pos']\n","  if pos == 'noun_prop':\n","    return 3\n","  result = lemma_db.get(lex)\n","  if result:\n","    if len(result) == 1:\n","      rl = result[0]['level']\n","    else:\n","      most_similar_element = None\n","      max_similarity = -1\n","\n","      for element in result:\n","          similarity = Levenshtein.ratio(pos, element['pos'])\n","          if similarity > max_similarity:\n","              max_similarity = similarity\n","              most_similar_element = element\n","\n","      rl = most_similar_element['level']\n","    return rl\n","  else:\n","    return oov_level\n","\n","\n","def get_rl_lexicon(token, analyses, oov_level = 0):\n","  analysis = score_then_level_then_llp(analyses)\n","\n","  return get_rl_single(analysis)\n","\n","def levels_pipeline(fragment, decision_1, decision_2, requires_disambig = False):\n","  tokens = [t.split('#')[0] for t in fragment.split(' ')]\n","  gt = [t.split('#')[1] for t in fragment.split(' ')]\n","\n","  if requires_disambig:\n","    analyses = [token.analyses for token in bert_disambig.disambiguate(tokens)]\n","  else:\n","    analyses = gt\n","\n","  # decision round 1:\n","  levels = [decision_1(token, analysis) for token, analysis in zip(tokens, analyses)]\n","\n","  # decision round 2:\n","  levels = [l if l != 0 else decision_2(t, a) for l, t, a in zip(levels, tokens, analyses)]\n","\n","  return {\n","      'levels': levels,\n","      'gts': gt,\n","  }\n","\n","pure_0 = [levels_pipeline(f, get_rl_0, get_rl_0) for f in frag_dev['0']]\n","pure_3 = [levels_pipeline(f, get_rl_3, get_rl_3) for f in frag_dev['0']]\n","pure_4 = [levels_pipeline(f, get_rl_4, get_rl_4) for f in frag_dev['0']]\n","pure_5 = [levels_pipeline(f, get_rl_5, get_rl_5) for f in frag_dev['0']]\n","\n","pure_freq = [levels_pipeline(f, get_rl_freq, get_rl_0) for f in frag_dev['0']]\n","pure_alt_freq = [levels_pipeline(f, get_rl_alt_freq, get_rl_0) for f in frag_dev['0']]\n","pure_mle = [levels_pipeline(f, get_rl_mle, get_rl_0) for f in frag_dev['0']]\n","\n","def level_keep0(l):\n","  if l > 0:\n","    if l < 3:\n","      return 3\n","    else:\n","      return l\n","  else:\n","    return 0\n"],"metadata":{"id":"0mYb_5LOVgQA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503348672,"user_tz":-240,"elapsed":78303,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"07c2651b-8ca5-4eff-a0cb-34546718de07"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["0.85\n","616\n"]}]},{"cell_type":"code","source":["\n","pure_lexicon = [levels_pipeline(f, get_rl_lexicon, get_rl_0, requires_disambig = True) for f in frag_dev['0']]\n"],"metadata":{"id":"1Se3cTXXiVdv","executionInfo":{"status":"ok","timestamp":1715503505915,"user_tz":-240,"elapsed":157246,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["pure_0 = [x['levels'] for x in pure_0]\n","pure_3 = [x['levels'] for x in pure_3]\n","pure_4 = [x['levels'] for x in pure_4]\n","pure_5 = [x['levels'] for x in pure_5]\n","\n","pure_freq = [x['levels'] for x in pure_freq]\n","pure_alt_freq = [x['levels'] for x in pure_alt_freq]\n","pure_mle = [x['levels'] for x in pure_mle]\n","pure_lexicon = [[l if l > 3 or l == 0 else 3 for l in x['levels']] for x in pure_lexicon]"],"metadata":{"id":"08xnlJ-VlgpE","executionInfo":{"status":"ok","timestamp":1715503505918,"user_tz":-240,"elapsed":30,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["pure_lexicon[0]"],"metadata":{"id":"KluHKFdemELO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503505919,"user_tz":-240,"elapsed":29,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"ca4eb756-aaef-4a61-80d3-ce94c7ce9905"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3, 3]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#### Check preformance when padded to 30? (only lose around 150 tokens)\n","bert_padded_decisions = []\n","\n","for x, y in zip(pure_alt_freq, res_wordwise_decisions[0]):\n","  y = y + [0 for x in range(len(x) - len(y))]\n","  bert_padded_decisions.append([l+3 for l in y])"],"metadata":{"id":"8iTjcNtqVElL","executionInfo":{"status":"ok","timestamp":1715503505919,"user_tz":-240,"elapsed":27,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["bert_padded_decisions[0]"],"metadata":{"id":"stt_-m9YELXX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503505919,"user_tz":-240,"elapsed":26,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"e5acbaa6-7896-4a24-f6d1-996ed66a1a29"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3, 3]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["len(pure_0)"],"metadata":{"id":"mnTv977XYRha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715503505920,"user_tz":-240,"elapsed":22,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"66a289a4-3d8c-4e29-99d3-dcf6487b5913"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2948"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["\n","\n","def comb_experiment_error_analysis_pipeline(decision_1, decision_2, decision_final, frags):\n","  all_mle = 0\n","  all_lex = 0\n","  all_bert = 0\n","  all_results = []\n","  for d1, d2, d3, f in zip(decision_1, decision_2, decision_final, frags):\n","    toks = [t.split('#')[0] for t in f.split(' ')]\n","    gts = [int(t.split('#')[1]) for t in f.split(' ')]\n","    gold_level = max(gts)\n","\n","    words_5 = [t for t, l in zip(toks, gts) if l == 5]\n","    words_4 = [t for t, l in zip(toks, gts) if l == 4]\n","    words_3 = [t for t, l in zip(toks, gts) if l == 3]\n","\n","    ### predictive process\n","    ## d2\n","\n","    round = ['mle' if l != 0 else 0 for l in d1]\n","\n","    decision = [dec if dec != 0 else alt for dec, alt in zip(d1, d2)]\n","\n","    round = ['lex' if r == 0 and d != 0 else r for r, d in zip(round, decision)]\n","\n","    decision = [dec if dec != 0 else alt for dec, alt in zip(decision, d3)]\n","\n","    round = ['bert' if r == 0 and d != 0 else r for r, d in zip(round, decision)]\n","\n","    all_mle += round.count('mle')\n","    all_bert += round.count('bert')\n","    all_lex += round.count('lex')\n","\n","    pred = max(decision)\n","\n","\n","    misidentified_5 = [\"{}/{}/{}\".format(t, d, r) for t, g, d, r in zip(toks, gts, decision, round) if (d != g and g == 5)]\n","    misidentified_4 = [\"{}/{}/{}\".format(t, d, r) for t, g, d, r in zip(toks, gts, decision, round) if (d != g and g == 4)]\n","    misidentified_3 = [\"{}/{}/{}\".format(t, d, r) for t, g, d, r in zip(toks, gts, decision, round) if (d != g and g == 3)]\n","\n","    all_errors = [' '.join([\"{}->{}->{}\".format(g, r, d) for t, g, d, r in zip(toks, gts, decision, round) if (d != g and g == x)]) for x in [3,4,5]]\n","\n","    all_results.append([\n","        ' '.join(toks),\n","        str(gold_level),\n","        str(pred),\n","        ' '.join(words_5),\n","        ' '.join(words_4),\n","        ' '.join(words_3),\n","        ' '.join(misidentified_5),\n","        ' '.join(misidentified_4),\n","        ' '.join(misidentified_3),\n","        ' '.join(all_errors),\n","        len(toks)\n","    ])\n","  return all_results, all_mle, all_lex, all_bert\n"],"metadata":{"id":"axv5X0cXXBAs","executionInfo":{"status":"ok","timestamp":1715504405578,"user_tz":-240,"elapsed":466,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q3cr9K_-8Bva","executionInfo":{"status":"ok","timestamp":1715504407148,"user_tz":-240,"elapsed":2,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["res_list, all_mle, all_lex, all_bert = comb_experiment_error_analysis_pipeline(pure_mle, pure_lexicon, bert_padded_decisions, frag_dev['0'])"],"metadata":{"id":"FeUIalRwk7pe","executionInfo":{"status":"ok","timestamp":1715504407598,"user_tz":-240,"elapsed":3,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["print([all_mle, all_lex, all_bert])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deZanomM8M4C","executionInfo":{"status":"ok","timestamp":1715504407598,"user_tz":-240,"elapsed":2,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"236f47b2-2c35-417a-a737-e6e15aab64c6"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[17058, 4843, 174]\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"FZO9YiK9Y5Y1"}},{"cell_type":"code","source":["final_result = pd.DataFrame(res_list, columns = ['frag','gt-frag','pred','words-5','words-4','words-3','misidentified-5','misidentified-4','misidentified-3', 'all_errors', 'length'])"],"metadata":{"id":"NGJITSr5TCso","executionInfo":{"status":"ok","timestamp":1715504409666,"user_tz":-240,"elapsed":2,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["sum(final_result['length'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4hoE-uBB_O-","executionInfo":{"status":"ok","timestamp":1715504433680,"user_tz":-240,"elapsed":4,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"4e5a0af4-6439-49e6-91cc-ec88e4a728ec"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22075"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["final_result.to_csv('/content/drive/My Drive/capstone_data/final_result/error_analysis.csv')"],"metadata":{"id":"IIu8zaZIqd4G","executionInfo":{"status":"aborted","timestamp":1715502871847,"user_tz":-240,"elapsed":17,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_result[:10\n","             ]"],"metadata":{"id":"Kadrm12irL0B","executionInfo":{"status":"aborted","timestamp":1715502871847,"user_tz":-240,"elapsed":14,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(final_result[final_result['gt-frag'] == final_result['pred']])"],"metadata":{"id":"zwi4lUVBhtG_","executionInfo":{"status":"aborted","timestamp":1715502871849,"user_tz":-240,"elapsed":15,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(final_result)"],"metadata":{"id":"uiPAEvONEBa_","executionInfo":{"status":"aborted","timestamp":1715502871851,"user_tz":-240,"elapsed":1221,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["2611/2948"],"metadata":{"id":"ZPkiGmbV12a5","executionInfo":{"status":"aborted","timestamp":1715502871852,"user_tz":-240,"elapsed":1214,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8LSU0ull2YuV","executionInfo":{"status":"aborted","timestamp":1715502871853,"user_tz":-240,"elapsed":1212,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":null,"outputs":[]}]}