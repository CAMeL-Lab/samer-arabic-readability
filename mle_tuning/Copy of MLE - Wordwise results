{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXj7rH7lfCaHIms3zGDedU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiPnyBTN3CaI","executionInfo":{"status":"ok","timestamp":1711526481175,"user_tz":-240,"elapsed":41433,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"0c482149-f988-4d11-ca8a-cc6de4361b1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import typing\n","import pandas as pd\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import classification_report\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","import math\n","\n","from sklearn.metrics import f1_score, accuracy_score, classification_report\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"code","source":["\n","!pip install camel_tools\n","\n","from camel_tools.tokenizers.word import simple_word_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wB1D-kxCOR3","executionInfo":{"status":"ok","timestamp":1711528620274,"user_tz":-240,"elapsed":338745,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"2c299e4f-6812-4d2e-d1c3-de6b7de9de25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting camel_tools\n","  Downloading camel_tools-1.5.2-py3-none-any.whl (124 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/124.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from camel_tools) (0.18.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.16.0)\n","Collecting docopt (from camel_tools)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from camel_tools) (5.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.11.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from camel_tools) (1.2.2)\n","Collecting dill (from camel_tools)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from camel_tools) (2.2.1+cu121)\n","Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from camel_tools) (4.38.2)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from camel_tools) (0.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from camel_tools) (2.31.0)\n","Collecting emoji (from camel_tools)\n","  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyrsistent (from camel_tools)\n","  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from camel_tools) (0.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from camel_tools) (4.66.2)\n","Collecting muddler (from camel_tools)\n","  Downloading muddler-0.1.3-py3-none-any.whl (16 kB)\n","Collecting camel-kenlm>=2023.3.17.2 (from camel_tools)\n","  Downloading camel-kenlm-2023.3.17.2.tar.gz (426 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m822.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->camel_tools)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->camel_tools) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->camel_tools)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.2->camel_tools) (0.4.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->camel_tools) (2023.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->camel_tools) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel_tools) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->camel_tools) (3.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->camel_tools) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->camel_tools) (1.3.0)\n","Building wheels for collected packages: camel-kenlm, docopt\n","  Building wheel for camel-kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for camel-kenlm: filename=camel_kenlm-2023.3.17.2-cp310-cp310-linux_x86_64.whl size=3453087 sha256=9952db17647fc308c809b5d8f12067009b6b78bc1db2a56f12a20d54a22dd3cf\n","  Stored in directory: /root/.cache/pip/wheels/29/c5/32/09633c3b70fdfc470b2fb912bd9e90d8d6814df68c794dcaa6\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=dc196b7ee591ec28de04e875bd51c3e71b1409ff9eb2c31c796445052b074c38\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built camel-kenlm docopt\n","Installing collected packages: docopt, camel-kenlm, pyrsistent, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, muddler, emoji, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, camel_tools\n","Successfully installed camel-kenlm-2023.3.17.2 camel_tools-1.5.2 dill-0.3.8 docopt-0.6.2 emoji-2.11.0 muddler-0.1.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pyrsistent-0.20.0\n"]}]},{"cell_type":"code","source":["## imports for training data\n","\n","base_path_aligned = '/content/drive/My Drive/capstone_data/bashar_data/capstone_data/readability_data'\n","dev_aligned = pd.read_csv(base_path_aligned + '/dev_pnx.tsv', sep = '\\t')\n","test_aligned = pd.read_csv(base_path_aligned + '/test_pnx.tsv', sep = '\\t')\n","train_aligned = pd.read_csv(base_path_aligned + '/train_pnx.tsv', sep = '\\t')\n","\n","base_path = '/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/'\n","\n","dev_levelled = pd.read_csv(base_path + 'dev_levelled.csv')\n","\n","train_levelled = pd.read_csv(base_path + 'train_levelled.csv')\n","\n","test_levelled = pd.read_csv(base_path + 'test_levelled.csv')\n","\n","dev_levelled = dev_levelled[dev_levelled.apply(lambda x: type(x['text']) == str, axis = 1)]\n","train_levelled = train_levelled[train_levelled.apply(lambda x: type(x['text']) == str, axis = 1)]\n","test_levelled = test_levelled[test_levelled.apply(lambda x: type(x['text']) == str, axis = 1)]\n","\n"],"metadata":{"id":"Fh1j-3Xn-jMC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","frag_train = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/all_train_aligned.csv')\n","frag_dev = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/all_dev_aligned.csv')\n","frag_test = pd.read_csv('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/all_test_aligned.csv')\n","\n","\n","frag_train = frag_train[frag_train.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_dev = frag_dev[frag_dev.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_test = frag_test[frag_test.apply(lambda x: type(x['0']) == str, axis = 1)]"],"metadata":{"id":"lpkSLwFj7Kxd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Strategy"],"metadata":{"id":"nrHShkFX8qMb"}},{"cell_type":"code","source":["def get_mle_counts(fragments, levels):\n","  frag_text = [[simple_word_tokenize(t), l] for t, l in tqdm(zip(fragments, levels))]\n","\n","  dict_levels = {}\n","  for frag in frag_text:\n","      text = frag[0]\n","      level = frag[1]\n","      for token in text:\n","          try:\n","              #assume every entry of dict_levels : {3: int, 4: int, 5: int}\n","              dict_levels[token][level] += 1\n","          except:\n","              dict_levels[token] = {3: 0, 4: 0, 5: 0}\n","              dict_levels[token][level] += 1\n","  return dict_levels\n","\n","def get_mle_counts_aligned(words, levels):\n","  dict_levels = {}\n","  for word, level in zip(words, levels):\n","      try:\n","          #assume every entry of dict_levels : {3: int, 4: int, 5: int}\n","          dict_levels[word][level] += 1\n","      except:\n","          dict_levels[word] = {3: 0, 4: 0, 5: 0}\n","          dict_levels[word][level] += 1\n","  return dict_levels\n","\n","def max_frequency_strategy(dict_levels):\n","  dict_levels_max = {}\n","  for token in dict_levels.keys():\n","    dict_levels_max[token] = max(dict_levels[token].items(), key = lambda x: x[1])[0]\n","  return dict_levels_max\n","\n","def weighted_average_strategy(dict_levels):\n","  dict_levels_avg = {}\n","  for token in dict_levels.keys():\n","    dict_levels_avg[token] = np.average(list(dict_levels[token].keys()), weights = list(dict_levels[token].values()))\n","  return dict_levels_avg"],"metadata":{"id":"Wug_H-nW7Ohp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Backoffs (freq)"],"metadata":{"id":"y6G-quMn8sMY"}},{"cell_type":"code","source":["import pickle\n","with open('/content/drive/My Drive/capstone_data/bashar_data/capstone_data/splits/freq_token_db.pkl', 'rb') as f:\n","  freq_backoff = pickle.load(f)"],"metadata":{"id":"UD1bpgQC81ih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Setups"],"metadata":{"id":"AISoueuH82KK"}},{"cell_type":"code","source":["def mle_training_pipeline(data, strategy):\n","  counts = get_mle_counts(data['text'], data['level'])\n","  return strategy(counts)\n","\n","def mle_training_pipeline_aligned(data, strategy):\n","  counts = get_mle_counts_aligned(data['Word'], data['Label'])\n","  return strategy(counts)\n","\n","def get_rl(token, model, oov_level = 0):\n","    try:\n","        return model[token]\n","    except:\n","        return oov_level\n","\n","\n","def mle_levels_inference_pipeline(fragment, model, backoff_freq = False):\n","  tokens = [t.split('#')[0] for t in fragment.split(' ')]\n","  levels = [get_rl(token, model, 0) for token in tokens]\n","\n","  if backoff_freq:\n","    levels = [a if a !=0 else get_rl(t, freq_backoff, 0) for a, t in zip(levels, tokens)]\n","\n","  levels = [round(a) if a > 3 else 3 for a in levels]\n","  return levels"],"metadata":{"id":"p6DzvziJ87of"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["highest_model = mle_training_pipeline(train_levelled, max_frequency_strategy)\n","weighted_avg_model = mle_training_pipeline(train_levelled, weighted_average_strategy)\n","highest_aligned_model = mle_training_pipeline_aligned(train_aligned, max_frequency_strategy)\n","weighted_aligned_model = mle_training_pipeline_aligned(train_aligned, weighted_average_strategy)"],"metadata":{"id":"oPCGdSvP9PX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_gt_levels(fragment):\n","  return [int(t.split('#')[1]) for t in fragment.split(' ')]\n","\n","gt_levels = np.concatenate([get_gt_levels(f) for f in frag_test['0']])"],"metadata":{"id":"mkLq1Ewh-Pim","executionInfo":{"status":"ok","timestamp":1711554013852,"user_tz":-240,"elapsed":6,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["#### Only eight experiments. Given that we are checking on word level, aggregation is not needed as an experimental variable"],"metadata":{"id":"JoMp_Lt2_JhG"}},{"cell_type":"code","source":["results_high_max = np.concatenate([mle_levels_inference_pipeline(a, highest_model) for a in frag_test['0']])\n","results_weight_max = np.concatenate([mle_levels_inference_pipeline(a, weighted_avg_model) for a in frag_test['0']])\n","results_high_max_aligned = np.concatenate([mle_levels_inference_pipeline(a, highest_aligned_model) for a in frag_test['0']])\n","results_weight_max_aligned = np.concatenate([mle_levels_inference_pipeline(a, weighted_aligned_model) for a in frag_test['0']])\n","results_high_max_backoff = np.concatenate([mle_levels_inference_pipeline(a, highest_model, backoff_freq = True) for a in frag_test['0']])\n","results_weight_max_backoff = np.concatenate([mle_levels_inference_pipeline(a, weighted_avg_model, backoff_freq = True) for a in frag_test['0']])\n","results_high_max_aligned_backoff = np.concatenate([mle_levels_inference_pipeline(a, highest_aligned_model, backoff_freq = True) for a in frag_test['0']])\n","results_weight_max_aligned_backoff = np.concatenate([mle_levels_inference_pipeline(a, weighted_aligned_model, backoff_freq = True) for a in frag_test['0']])\n","\n"],"metadata":{"id":"O6TxvmS4-rrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('--------------------ALIGNED')\n","print('--------------------high-max')\n","print(classification_report(gt_levels, results_high_max_aligned))\n","print('--------------------weight-max')\n","print(classification_report(gt_levels, results_weight_max_aligned))\n","print('--------------------NOT ALIGNED')\n","print('--------------------high-max')\n","print(classification_report(gt_levels, results_high_max))\n","print('--------------------weight-max')\n","print(classification_report(gt_levels, results_weight_max))\n","\n","print('===================bakckoff freq')\n","print('--------------------ALIGNED')\n","print('--------------------high-max')\n","print(classification_report(gt_levels, results_high_max_aligned_backoff))\n","print('--------------------weight-max')\n","print(classification_report(gt_levels, results_weight_max_aligned_backoff))\n","print('--------------------NOT ALIGNED')\n","print('--------------------high-max')\n","print(classification_report(gt_levels, results_high_max_backoff))\n","print('--------------------weight-max')\n","print(classification_report(gt_levels, results_weight_max_backoff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcUyqosjA8bP","executionInfo":{"status":"ok","timestamp":1711540468117,"user_tz":-240,"elapsed":751,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"}},"outputId":"1f34adc0-4d74-4410-c182-26e14ac62e0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.93      1.00      0.96     23851\n","           4       0.91      0.45      0.60      2032\n","           5       0.83      0.24      0.37      1040\n","\n","    accuracy                           0.93     26923\n","   macro avg       0.89      0.56      0.64     26923\n","weighted avg       0.92      0.93      0.91     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.93      0.99      0.96     23851\n","           4       0.86      0.46      0.60      2032\n","           5       0.84      0.24      0.37      1040\n","\n","    accuracy                           0.92     26923\n","   macro avg       0.88      0.56      0.64     26923\n","weighted avg       0.92      0.92      0.91     26923\n","\n","--------------------NOT ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.93      0.99      0.96     23851\n","           4       0.89      0.45      0.60      2032\n","           5       0.82      0.24      0.38      1040\n","\n","    accuracy                           0.92     26923\n","   macro avg       0.88      0.56      0.65     26923\n","weighted avg       0.92      0.92      0.91     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.86      0.42      0.56     23851\n","           4       0.07      0.56      0.13      2032\n","           5       0.85      0.24      0.37      1040\n","\n","    accuracy                           0.42     26923\n","   macro avg       0.59      0.40      0.36     26923\n","weighted avg       0.80      0.42      0.52     26923\n","\n","===================bakckoff freq\n","--------------------ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.98      0.90      0.93     23851\n","           4       0.48      0.58      0.53      2032\n","           5       0.29      0.72      0.41      1040\n","\n","    accuracy                           0.86     26923\n","   macro avg       0.58      0.73      0.62     26923\n","weighted avg       0.91      0.86      0.88     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.98      0.89      0.93     23851\n","           4       0.48      0.59      0.53      2032\n","           5       0.29      0.72      0.41      1040\n","\n","    accuracy                           0.86     26923\n","   macro avg       0.58      0.74      0.62     26923\n","weighted avg       0.91      0.86      0.88     26923\n","\n","--------------------NOT ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.98      0.90      0.94     23851\n","           4       0.50      0.58      0.54      2032\n","           5       0.29      0.72      0.42      1040\n","\n","    accuracy                           0.87     26923\n","   macro avg       0.59      0.74      0.63     26923\n","weighted avg       0.91      0.87      0.89     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.97      0.32      0.48     23851\n","           4       0.09      0.69      0.15      2032\n","           5       0.29      0.72      0.41      1040\n","\n","    accuracy                           0.37     26923\n","   macro avg       0.45      0.58      0.35     26923\n","weighted avg       0.88      0.37      0.46     26923\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_Vo27eCyFhr_"},"execution_count":null,"outputs":[]}]}