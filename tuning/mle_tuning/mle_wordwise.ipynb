{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41433,"status":"ok","timestamp":1711526481175,"user":{"displayName":"Juan Pi単eros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"kiPnyBTN3CaI","outputId":"0c482149-f988-4d11-ca8a-cc6de4361b1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["## Objective - MLE Wordwise Training and Parameter Optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338745,"status":"ok","timestamp":1711528620274,"user":{"displayName":"Juan Pi単eros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"0wB1D-kxCOR3","outputId":"2c299e4f-6812-4d2e-d1c3-de6b7de9de25"},"outputs":[],"source":["from camel_tools.tokenizers.word import simple_word_tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fh1j-3Xn-jMC"},"outputs":[],"source":["## imports for training data\n","\n","base_path_aligned = '../../data/readability_data'\n","dev_aligned = pd.read_csv(base_path_aligned + '/dev_pnx.tsv', sep = '\\t')\n","test_aligned = pd.read_csv(base_path_aligned + '/test_pnx.tsv', sep = '\\t')\n","train_aligned = pd.read_csv(base_path_aligned + '/train_pnx.tsv', sep = '\\t')\n","\n","base_path = '../../data/splits/levelled_fragments/'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpkSLwFj7Kxd"},"outputs":[],"source":["frag_train = pd.read_csv('../data/all_train_aligned.csv')\n","frag_dev = pd.read_csv('../data/all_dev_aligned.csv')\n","frag_test = pd.read_csv('../data/all_test_aligned.csv')\n","\n","\n","frag_train = frag_train[frag_train.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_dev = frag_dev[frag_dev.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_test = frag_test[frag_test.apply(lambda x: type(x['0']) == str, axis = 1)]"]},{"cell_type":"markdown","metadata":{"id":"nrHShkFX8qMb"},"source":["### Strategy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wug_H-nW7Ohp"},"outputs":[],"source":["def get_mle_counts_aligned(words, levels):\n","  dict_levels = {}\n","  for word, level in zip(words, levels):\n","      try:\n","          #assume every entry of dict_levels : {3: int, 4: int, 5: int}\n","          dict_levels[word][level] += 1\n","      except:\n","          dict_levels[word] = {3: 0, 4: 0, 5: 0}\n","          dict_levels[word][level] += 1\n","  return dict_levels\n","\n","def max_frequency_strategy(dict_levels):\n","  dict_levels_max = {}\n","  for token in dict_levels.keys():\n","    dict_levels_max[token] = max(dict_levels[token].items(), key = lambda x: x[1])[0]\n","  return dict_levels_max\n","\n","def weighted_average_strategy(dict_levels):\n","  dict_levels_avg = {}\n","  for token in dict_levels.keys():\n","    dict_levels_avg[token] = np.average(list(dict_levels[token].keys()), weights = list(dict_levels[token].values()))\n","  return dict_levels_avg"]},{"cell_type":"markdown","metadata":{"id":"AISoueuH82KK"},"source":["### Setups"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6DzvziJ87of"},"outputs":[],"source":["\n","\n","def mle_training_pipeline_aligned(data, strategy):\n","  counts = get_mle_counts_aligned(data['Word'], data['Label'])\n","  return strategy(counts)\n","\n","def get_rl(token, model, oov_level = 0):\n","    try:\n","        return model[token]\n","    except:\n","        return oov_level\n","\n","\n","def mle_levels_inference_pipeline(fragment, model, backoff_freq = False):\n","  tokens = [t.split('#')[0] for t in fragment.split(' ')]\n","  levels = [get_rl(token, model, 0) for token in tokens]\n","  levels = [round(a) if a > 3 else 3 for a in levels]\n","  return levels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oPCGdSvP9PX6"},"outputs":[],"source":["highest_aligned_model = mle_training_pipeline_aligned(train_aligned, max_frequency_strategy)\n","weighted_aligned_model = mle_training_pipeline_aligned(train_aligned, weighted_average_strategy)"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711554013852,"user":{"displayName":"Juan Pi単eros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"mkLq1Ewh-Pim"},"outputs":[],"source":["def get_gt_levels(fragment):\n","  return [int(t.split('#')[1]) for t in fragment.split(' ')]\n","\n","gt_levels = np.concatenate([get_gt_levels(f) for f in frag_test['0']])"]},{"cell_type":"markdown","metadata":{"id":"JoMp_Lt2_JhG"},"source":["#### Only eight experiments. Given that we are checking on word level, aggregation is not needed as an experimental variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6TxvmS4-rrW"},"outputs":[],"source":["res = [ np.concatenate([mle_levels_inference_pipeline(a, highest_aligned_model) for a in frag_test['0']])\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1711540468117,"user":{"displayName":"Juan Pi単eros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"jcUyqosjA8bP","outputId":"1f34adc0-4d74-4410-c182-26e14ac62e0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.93      1.00      0.96     23851\n","           4       0.91      0.45      0.60      2032\n","           5       0.83      0.24      0.37      1040\n","\n","    accuracy                           0.93     26923\n","   macro avg       0.89      0.56      0.64     26923\n","weighted avg       0.92      0.93      0.91     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.93      0.99      0.96     23851\n","           4       0.86      0.46      0.60      2032\n","           5       0.84      0.24      0.37      1040\n","\n","    accuracy                           0.92     26923\n","   macro avg       0.88      0.56      0.64     26923\n","weighted avg       0.92      0.92      0.91     26923\n","\n","--------------------NOT ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.93      0.99      0.96     23851\n","           4       0.89      0.45      0.60      2032\n","           5       0.82      0.24      0.38      1040\n","\n","    accuracy                           0.92     26923\n","   macro avg       0.88      0.56      0.65     26923\n","weighted avg       0.92      0.92      0.91     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.86      0.42      0.56     23851\n","           4       0.07      0.56      0.13      2032\n","           5       0.85      0.24      0.37      1040\n","\n","    accuracy                           0.42     26923\n","   macro avg       0.59      0.40      0.36     26923\n","weighted avg       0.80      0.42      0.52     26923\n","\n","===================bakckoff freq\n","--------------------ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.98      0.90      0.93     23851\n","           4       0.48      0.58      0.53      2032\n","           5       0.29      0.72      0.41      1040\n","\n","    accuracy                           0.86     26923\n","   macro avg       0.58      0.73      0.62     26923\n","weighted avg       0.91      0.86      0.88     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.98      0.89      0.93     23851\n","           4       0.48      0.59      0.53      2032\n","           5       0.29      0.72      0.41      1040\n","\n","    accuracy                           0.86     26923\n","   macro avg       0.58      0.74      0.62     26923\n","weighted avg       0.91      0.86      0.88     26923\n","\n","--------------------NOT ALIGNED\n","--------------------high-max\n","              precision    recall  f1-score   support\n","\n","           3       0.98      0.90      0.94     23851\n","           4       0.50      0.58      0.54      2032\n","           5       0.29      0.72      0.42      1040\n","\n","    accuracy                           0.87     26923\n","   macro avg       0.59      0.74      0.63     26923\n","weighted avg       0.91      0.87      0.89     26923\n","\n","--------------------weight-max\n","              precision    recall  f1-score   support\n","\n","           3       0.97      0.32      0.48     23851\n","           4       0.09      0.69      0.15      2032\n","           5       0.29      0.72      0.41      1040\n","\n","    accuracy                           0.37     26923\n","   macro avg       0.45      0.58      0.35     26923\n","weighted avg       0.88      0.37      0.46     26923\n","\n"]}],"source":["\n","print(classification_report(gt_levels, results_high_max_aligned))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Vo27eCyFhr_"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMXj7rH7lfCaHIms3zGDedU","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
