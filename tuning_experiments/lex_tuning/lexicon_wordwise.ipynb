{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":245454,"status":"ok","timestamp":1711614080318,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"DO6CzdpO1MHr","outputId":"2ae302ff-a307-49aa-dd52-d92499640cbb"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report\n","import math\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import Levenshtein\n","\n","import os\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28445,"status":"ok","timestamp":1711614118498,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"dEkC4qfJ3Nk4","outputId":"d5529e14-3817-43c3-e225-3bc76c033b98"},"outputs":[],"source":["from camel_tools.morphology.database import MorphologyDB\n","from camel_tools.morphology.analyzer import Analyzer\n","from camel_tools.tokenizers.word import simple_word_tokenize\n","from camel_tools.disambig.mle import MLEDisambiguator\n","from camel_tools.disambig.bert import BERTUnfactoredDisambiguator\n","from pathlib import Path\n","S31_DB_PATH = Path('../../data/disambig_db/calima-msa-s31.db')\n","S31_DB = MorphologyDB(S31_DB_PATH, 'a')\n","S31_AN = Analyzer(S31_DB, 'NOAN_ALL', cache_size=100000)\n","bert_disambig = BERTUnfactoredDisambiguator.pretrained('msa', top=1000, pretrained_cache = False)\n","bert_disambig._analyzer = S31_AN"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2511,"status":"ok","timestamp":1711614120977,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"I4M7QHm64hqt"},"outputs":[],"source":["frag_train = pd.read_csv('../../data/all_train_aligned.csv')\n","frag_dev = pd.read_csv('../../data/all_dev_aligned.csv')\n","frag_test = pd.read_csv('../../data/all_test_aligned.csv')\n","\n","\n","frag_train = frag_train[frag_train.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_dev = frag_dev[frag_dev.apply(lambda x: type(x['0']) == str, axis = 1)]\n","frag_test = frag_test[frag_test.apply(lambda x: type(x['0']) == str, axis = 1)]"]},{"cell_type":"markdown","metadata":{"id":"XgbK61gL8nSe"},"source":["Import lexicon DB and readability level pipeline\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1200,"status":"ok","timestamp":1711614122161,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"iPbrf5gh8ph1"},"outputs":[],"source":["import pickle\n","with open('../../data/lemma_db/quick_lemma_lookup.pkl', 'rb') as f:\n","    lemma_db = pickle.load(f)\n","\n","def get_readability_level(analysis, token, oov_management, default_level = 0):\n","  lex = analysis['lex']\n","  pos = analysis['pos']\n","  result = lemma_db.get(lex)\n","  if result:\n","    if len(result) == 1:\n","      rl = result[0]['level']\n","    else:\n","      most_similar_element = None\n","      max_similarity = -1\n","\n","      for element in result:\n","          similarity = Levenshtein.ratio(pos, element['pos'])\n","          if similarity > max_similarity:\n","              max_similarity = similarity\n","              most_similar_element = element\n","\n","      rl = most_similar_element['level']\n","  else:\n","    rl = oov_management(token, default_level, analysis)\n","  return rl"]},{"cell_type":"markdown","metadata":{"id":"12ELPILJ8qH_"},"source":["Analysis tiebreaking"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1711614122164,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"DaY4PeNn8xg-"},"outputs":[],"source":["def sort_score(list_of_analyses):\n","  list_of_analyses.sort(key = lambda x: x.score, reverse = True)\n","  highest_score = list_of_analyses[0].score\n","  analyses_with_equal_score = [x for x in list_of_analyses\n","                                if x.score == highest_score]\n","  return analyses_with_equal_score\n","\n","\n","def sort_lexlogprob(list_of_analyses):\n","  list_of_analyses.sort(key = lambda x: x.analysis['lex_logprob'], reverse=True)\n","  highest_prob = list_of_analyses[0].analysis['lex_logprob']\n","  analyses_with_equal_prob = [x for x in list_of_analyses\n","                                if x.analysis['lex_logprob'] == highest_prob]\n","  return analyses_with_equal_prob\n","\n","def sort_level(list_of_analyses):\n","  list_of_analyses.sort(key = lambda x: get_readability_level(x.analysis, '', default_level_oov, 9999))\n","  lowest_rl = get_readability_level(list_of_analyses[0].analysis, '', default_level_oov, 9999)\n","  analyses_with_equal_level = [x for x in list_of_analyses\n","                                    if get_readability_level(x.analysis, '', default_level_oov, 9999) == lowest_rl]\n","  return analyses_with_equal_level\n","\n","\n","def score_then_llp(list_of_analyses):\n","  list_of_analyses = sort_score(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_lexlogprob(list_of_analyses)\n","  return list_of_analyses[0].analysis\n","\n","\n","def score_then_level(list_of_analyses):\n","  list_of_analyses = sort_score(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_level(list_of_analyses)\n","  return list_of_analyses[0].analysis\n","\n","def score_then_llp_then_level(list_of_analyses):\n","  list_of_analyses = sort_score(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_lexlogprob(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_level(list_of_analyses)\n","  return list_of_analyses[0].analysis\n","\n","\n","def score_then_level_then_llp(list_of_analyses):\n","  list_of_analyses = sort_score(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_level(list_of_analyses)\n","  if len(list_of_analyses) == 1:\n","    return list_of_analyses[0].analysis\n","\n","  list_of_analyses = sort_lexlogprob(list_of_analyses)\n","  return list_of_analyses[0].analysis\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_wO6gV1n8zVs"},"source":["OOV Management"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14920,"status":"ok","timestamp":1711614137062,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"yh5m_Z_E9Yh7"},"outputs":[],"source":["with open('../../data/levels_db/mle_max_aligned_model.pkl', 'rb') as f:\n","  mle_model = pickle.load(f)\n","\n","with open('../../data/freq/freq_token_db.pkl', 'rb') as f:\n","  freq_backoff = pickle.load(f)\n","\n","def default_level_oov(word, level, analysis):\n","  return level\n","\n","def default_level_nounprop(word, level, analysis):\n","  if analysis['pos'] == 'NOUN_PROP':\n","    return level\n","  else:\n","    return 5\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jhIPRGrU9Y4B"},"source":["Inference pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1711614137069,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"PG8adHvcgt_1"},"outputs":[],"source":["def lexicon_levels_pipeline(fragment, tiebreak, oov_management):\n","  tokens = [t.split('#')[0] for t in fragment.split(' ')]\n","  analyses = [token.analyses for token in bert_disambig.disambiguate(tokens)]\n","  picked_lexs = [tiebreak(analysis) for analysis in analyses]\n","  levels = [\n","      get_readability_level(analysis, token, oov_management) for analysis, token in zip(picked_lexs, tokens)\n","  ]\n","  levels = [a if a > 3 else 3 for a in levels]\n","  return levels"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1711614137070,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"17TPA5OZg5RR"},"outputs":[],"source":["def get_gt_levels(fragment):\n","  return [int(t.split('#')[1]) for t in fragment.split(' ')]\n","\n","gt_levels = np.concatenate([get_gt_levels(f) for f in frag_test['0']])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3214312,"status":"ok","timestamp":1711617351361,"user":{"displayName":"Juan Piñeros Liberato","userId":"07905555678439108668"},"user_tz":-240},"id":"Z4y-pF8NoA6o"},"outputs":[],"source":["all_exps = [\n","    np.concatenate([lexicon_levels_pipeline(fragment, score_then_llp, default_level_oov) for fragment in (frag_test['0'])]),\n","    np.concatenate([lexicon_levels_pipeline(fragment, score_then_level, default_level_oov) for fragment in (frag_test['0'])]),\n","    np.concatenate([lexicon_levels_pipeline(fragment, score_then_llp_then_level, default_level_oov) for fragment in (frag_test['0'])]),\n","    np.concatenate([lexicon_levels_pipeline(fragment, score_then_level_then_llp, default_level_oov) for fragment in (frag_test['0'])]),\n","]\n","\n","def results_to_csv(result_arr):\n","  all_rows = []\n","  for resu in result_arr:\n","    inv_report = classification_report(gt_levels, resu, output_dict = True)\n","\n","    arr_inv = np.concatenate([[inv_report[x]['f1-score'],\n","            inv_report[x]['precision'],\n","            inv_report[x]['recall'],] for x in ['3', '4', '5']])\n","    arr_inv = np.append(arr_inv, inv_report['accuracy'])\n","    arr_inv = np.append(arr_inv, inv_report['macro avg']['f1-score'])\n","\n","\n","\n","    all_rows.append(arr_inv)\n","\n","  return all_rows\n","\n","pd.DataFrame(results_to_csv(res), columns= ['f1_3','3_prec','3_recall','f1_4','4_prec','4_recall','f1_5','5_prec','5_recall','accuracy','f1_macro'])\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNZZFRsMFW3MSGzyZPkYTmL","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
